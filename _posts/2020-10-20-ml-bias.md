---
layout: post
title: "Machine learning bias"
author: "Ankit"
tags: airflow
excerpt_separator: <!--more-->
---

### Let's learn about types of Bias in AI / ML

+ Historical bias occurs when the state of the world in which the data was generated is flawed.

+ Representation bias occurs when building datasets for training a model, if those datasets poorly represent the people that the model will serve.

+ Measurement bias occurs when the accuracy of the data varies across groups. This can happen when working with proxy variables if the quality of the proxy varies in different groups.

+ Aggregation bias occurs when groups are inappropriately combined, resulting in a model that does not perform well for any group or only performs well for the majority group

+ Evaluation bias occurs when evaluating a model, if the benchmark data (used to compare the model to other models that perform similar tasks) does not represent the population that the model will serve.

+ Deployment bias occurs when the problem the model is intended to solve is different from the way it is actually used. If the end users donâ€™t use the model in the way it is intended, there is no guarantee that the model will perform well.

[Paper](https://arxiv.org/pdf/1901.10002.pdf)

![ML bias](/assets/bias.png)